{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Salt Crystal Purity Classification - YOLOv8 Training\n",
    "\n",
    "This notebook trains a YOLOv8 model to classify salt crystals as **pure** or **impure**.\n",
    "\n",
    "## Requirements\n",
    "- Dataset labeled in Label Studio (YOLO format), zipped\n",
    "- Google Colab with GPU runtime\n",
    "\n",
    "## Before Starting\n",
    "1. Go to **Runtime > Change runtime type**\n",
    "2. Select **T4 GPU** (or any available GPU)\n",
    "3. Click **Save**"
   ],
   "metadata": {
    "id": "intro"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Step 1: Check GPU & Install Dependencies"
   ],
   "metadata": {
    "id": "step1_header"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "check_gpu"
   },
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Install Ultralytics (YOLOv8)\n",
    "!pip install ultralytics -q\n",
    "\n",
    "# Verify installation\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ],
   "metadata": {
    "id": "install_ultralytics"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 2: Mount Google Drive & Load Dataset\n\nYour dataset is stored in Google Drive at `MyDrive/salt-crystal/data.zip`",
   "metadata": {
    "id": "step2_header"
   }
  },
  {
   "cell_type": "code",
   "source": "from google.colab import drive\nimport zipfile\nimport os\n\n# Mount Google Drive\nprint(\"Mounting Google Drive...\")\ndrive.mount('/content/drive')\n\n# Path to your dataset in Google Drive\nzip_path = '/content/drive/MyDrive/salt-crystal/data.zip'\n\n# Verify the file exists\nif os.path.exists(zip_path):\n    print(f\"\\nDataset found: {zip_path}\")\nelse:\n    print(f\"\\nERROR: Dataset not found at {zip_path}\")\n    print(\"Please check the path and try again.\")\n\n# Extract the dataset\nprint(\"\\nExtracting dataset...\")\nwith zipfile.ZipFile(zip_path, 'r') as zip_ref:\n    zip_ref.extractall('/content/dataset')\n\nprint(\"Dataset extracted successfully!\")\nprint(\"\\nExtracted contents:\")\n!ls -la /content/dataset",
   "metadata": {
    "id": "upload_dataset"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Explore the dataset structure to find images and labels folders\n",
    "import os\n",
    "\n",
    "def list_directory(path, indent=0):\n",
    "    \"\"\"List directory contents recursively (2 levels deep)\"\"\"\n",
    "    if indent > 2:\n",
    "        return\n",
    "    try:\n",
    "        items = os.listdir(path)\n",
    "        for item in items[:10]:  # Limit to 10 items\n",
    "            full_path = os.path.join(path, item)\n",
    "            if os.path.isdir(full_path):\n",
    "                print(\"  \" * indent + f\"[DIR] {item}/\")\n",
    "                list_directory(full_path, indent + 1)\n",
    "            else:\n",
    "                print(\"  \" * indent + f\"      {item}\")\n",
    "        if len(items) > 10:\n",
    "            print(\"  \" * indent + f\"      ... and {len(items) - 10} more files\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "print(\"Dataset structure:\")\n",
    "print(\"=\"*50)\n",
    "list_directory('/content/dataset')"
   ],
   "metadata": {
    "id": "explore_structure"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "---\n## Step 3: Verify Dataset Paths\n\nLabel Studio exports data with `images/` and `labels/` folders. Let's verify the paths.",
   "metadata": {
    "id": "step3_header"
   }
  },
  {
   "cell_type": "code",
   "source": "# Label Studio YOLO export structure:\n# - images/    (contains all images)\n# - labels/    (contains YOLO format .txt files)\n# - classes.txt (contains class names)\n\nSOURCE_IMAGES = '/content/dataset/images'\nSOURCE_LABELS = '/content/dataset/labels'\n\n# Verify paths exist\nimport os\n\nif os.path.exists(SOURCE_IMAGES):\n    num_images = len([f for f in os.listdir(SOURCE_IMAGES) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n    print(f\"Images folder found: {SOURCE_IMAGES}\")\n    print(f\"  Contains {num_images} images\")\nelse:\n    print(f\"WARNING: Images folder NOT found at {SOURCE_IMAGES}\")\n\nif os.path.exists(SOURCE_LABELS):\n    num_labels = len([f for f in os.listdir(SOURCE_LABELS) if f.endswith('.txt')])\n    print(f\"Labels folder found: {SOURCE_LABELS}\")\n    print(f\"  Contains {num_labels} label files\")\nelse:\n    print(f\"WARNING: Labels folder NOT found at {SOURCE_LABELS}\")\n\n# Check classes.txt\nclasses_file = '/content/dataset/classes.txt'\nif os.path.exists(classes_file):\n    with open(classes_file, 'r') as f:\n        classes = [line.strip() for line in f.readlines() if line.strip()]\n    print(f\"\\nClasses found in classes.txt:\")\n    for i, cls in enumerate(classes):\n        print(f\"  {i}: {cls}\")\nelse:\n    print(f\"\\nWARNING: classes.txt not found at {classes_file}\")",
   "metadata": {
    "id": "configure_paths"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Step 4: Organize Dataset (Train/Validation Split)"
   ],
   "metadata": {
    "id": "step4_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "# Create train/valid directories\n",
    "os.makedirs('/content/dataset/train/images', exist_ok=True)\n",
    "os.makedirs('/content/dataset/train/labels', exist_ok=True)\n",
    "os.makedirs('/content/dataset/valid/images', exist_ok=True)\n",
    "os.makedirs('/content/dataset/valid/labels', exist_ok=True)\n",
    "\n",
    "# Get all image files\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
    "image_files = [f for f in os.listdir(SOURCE_IMAGES) if f.lower().endswith(image_extensions)]\n",
    "\n",
    "print(f\"Found {len(image_files)} images\")\n",
    "\n",
    "# Shuffle for random split\n",
    "random.seed(42)  # For reproducibility\n",
    "random.shuffle(image_files)\n",
    "\n",
    "# Split 90% train, 10% validation\n",
    "split_idx = int(len(image_files) * 0.9)\n",
    "train_files = image_files[:split_idx]\n",
    "valid_files = image_files[split_idx:]\n",
    "\n",
    "print(f\"Training set: {len(train_files)} images\")\n",
    "print(f\"Validation set: {len(valid_files)} images\")\n",
    "\n",
    "# Copy files to train folder\n",
    "print(\"\\nCopying training files...\")\n",
    "for img in train_files:\n",
    "    # Copy image\n",
    "    shutil.copy(os.path.join(SOURCE_IMAGES, img), '/content/dataset/train/images/')\n",
    "    # Copy corresponding label\n",
    "    label = os.path.splitext(img)[0] + '.txt'\n",
    "    label_path = os.path.join(SOURCE_LABELS, label)\n",
    "    if os.path.exists(label_path):\n",
    "        shutil.copy(label_path, '/content/dataset/train/labels/')\n",
    "\n",
    "# Copy files to valid folder\n",
    "print(\"Copying validation files...\")\n",
    "for img in valid_files:\n",
    "    # Copy image\n",
    "    shutil.copy(os.path.join(SOURCE_IMAGES, img), '/content/dataset/valid/images/')\n",
    "    # Copy corresponding label\n",
    "    label = os.path.splitext(img)[0] + '.txt'\n",
    "    label_path = os.path.join(SOURCE_LABELS, label)\n",
    "    if os.path.exists(label_path):\n",
    "        shutil.copy(label_path, '/content/dataset/valid/labels/')\n",
    "\n",
    "print(\"\\nDataset organization complete!\")\n",
    "print(f\"Train images: {len(os.listdir('/content/dataset/train/images'))}\")\n",
    "print(f\"Train labels: {len(os.listdir('/content/dataset/train/labels'))}\")\n",
    "print(f\"Valid images: {len(os.listdir('/content/dataset/valid/images'))}\")\n",
    "print(f\"Valid labels: {len(os.listdir('/content/dataset/valid/labels'))}\")"
   ],
   "metadata": {
    "id": "organize_dataset"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Step 5: Create Dataset Configuration (YAML)"
   ],
   "metadata": {
    "id": "step5_header"
   }
  },
  {
   "cell_type": "code",
   "source": "# Read class names from Label Studio's classes.txt\nclasses_file = '/content/dataset/classes.txt'\n\nwith open(classes_file, 'r') as f:\n    classes = [line.strip() for line in f.readlines() if line.strip()]\n\nprint(f\"Found {len(classes)} classes: {classes}\")\n\n# Build YAML configuration dynamically\nyaml_lines = [\n    \"path: /content/dataset\",\n    \"train: train/images\",\n    \"val: valid/images\",\n    \"\",\n    \"names:\"\n]\n\nfor i, cls in enumerate(classes):\n    yaml_lines.append(f\"  {i}: {cls}\")\n\nyaml_content = \"\\n\".join(yaml_lines)\n\n# Write YAML file\nwith open('/content/dataset/salt_crystal.yaml', 'w') as f:\n    f.write(yaml_content)\n\nprint(\"\\nDataset configuration file created!\")\nprint(\"=\"*50)\nprint(yaml_content)",
   "metadata": {
    "id": "create_yaml"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Verify class labels in your dataset\n",
    "# Check a few label files to confirm class IDs match\n",
    "import os\n",
    "\n",
    "label_dir = '/content/dataset/train/labels'\n",
    "label_files = os.listdir(label_dir)[:3]\n",
    "\n",
    "print(\"Sample label files content:\")\n",
    "print(\"(Format: class_id x_center y_center width height)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for lf in label_files:\n",
    "    print(f\"\\n{lf}:\")\n",
    "    with open(os.path.join(label_dir, lf), 'r') as f:\n",
    "        content = f.read().strip()\n",
    "        print(content if content else \"  (empty file)\")"
   ],
   "metadata": {
    "id": "verify_labels"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Step 6: Train YOLOv8 Model\n",
    "\n",
    "### Model Options:\n",
    "| Model | Size | Speed | Accuracy |\n",
    "|-------|------|-------|----------|\n",
    "| yolov8n.pt | Nano | Fastest | Good |\n",
    "| yolov8s.pt | Small | Fast | Better |\n",
    "| yolov8m.pt | Medium | Moderate | High |\n",
    "| yolov8l.pt | Large | Slower | Highest |"
   ],
   "metadata": {
    "id": "step6_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLOv8 model\n",
    "# Change to 'yolov8s.pt' or 'yolov8m.pt' for better accuracy\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train the model\n",
    "results = model.train(\n",
    "    data='/content/dataset/salt_crystal.yaml',\n",
    "    epochs=100,           # Number of training epochs\n",
    "    imgsz=640,            # Image size\n",
    "    batch=16,             # Batch size (reduce to 8 if memory error)\n",
    "    patience=20,          # Early stopping patience\n",
    "    save=True,            # Save checkpoints\n",
    "    project='/content/runs',\n",
    "    name='salt_crystal_model',\n",
    "    exist_ok=True,        # Overwrite if exists\n",
    "    pretrained=True,      # Use pretrained weights\n",
    "    optimizer='auto',     # Automatic optimizer selection\n",
    "    verbose=True,         # Print training progress\n",
    "    seed=42               # For reproducibility\n",
    ")"
   ],
   "metadata": {
    "id": "train_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Step 7: Evaluate Model Performance"
   ],
   "metadata": {
    "id": "step7_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the best trained model\n",
    "model = YOLO('/content/runs/salt_crystal_model/weights/best.pt')\n",
    "\n",
    "# Validate on validation set\n",
    "metrics = model.val()\n",
    "\n",
    "# Print metrics\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"MODEL PERFORMANCE METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"mAP50:      {metrics.box.map50:.4f}  (Mean Average Precision @ IoU 50%)\")\n",
    "print(f\"mAP50-95:   {metrics.box.map:.4f}  (Mean AP across IoU thresholds)\")\n",
    "print(f\"Precision:  {metrics.box.mp:.4f}  (How many detections are correct)\")\n",
    "print(f\"Recall:     {metrics.box.mr:.4f}  (How many objects were detected)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "if metrics.box.map50 > 0.7:\n",
    "    print(\"\\nModel performance is GOOD!\")\n",
    "elif metrics.box.map50 > 0.5:\n",
    "    print(\"\\nModel performance is ACCEPTABLE. Consider more training data for improvement.\")\n",
    "else:\n",
    "    print(\"\\nModel performance needs improvement. Try:\\n- More labeled images\\n- Larger model (yolov8s.pt)\\n- More epochs\")"
   ],
   "metadata": {
    "id": "evaluate_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# View training results plots\n",
    "from IPython.display import Image, display\n",
    "import os\n",
    "\n",
    "results_dir = '/content/runs/salt_crystal_model'\n",
    "\n",
    "# Display confusion matrix\n",
    "if os.path.exists(f'{results_dir}/confusion_matrix.png'):\n",
    "    print(\"Confusion Matrix:\")\n",
    "    display(Image(filename=f'{results_dir}/confusion_matrix.png', width=600))\n",
    "\n",
    "# Display training results\n",
    "if os.path.exists(f'{results_dir}/results.png'):\n",
    "    print(\"\\nTraining Results:\")\n",
    "    display(Image(filename=f'{results_dir}/results.png', width=800))"
   ],
   "metadata": {
    "id": "view_training_plots"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Step 8: Test Predictions on Sample Images"
   ],
   "metadata": {
    "id": "step8_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from ultralytics import YOLO\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Load trained model\n",
    "model = YOLO('/content/runs/salt_crystal_model/weights/best.pt')\n",
    "\n",
    "# Run inference on validation images\n",
    "results = model.predict(\n",
    "    source='/content/dataset/valid/images',\n",
    "    save=True,\n",
    "    conf=0.5,  # Confidence threshold\n",
    "    project='/content/runs',\n",
    "    name='predictions',\n",
    "    exist_ok=True\n",
    ")\n",
    "\n",
    "print(\"Predictions complete!\")"
   ],
   "metadata": {
    "id": "run_predictions"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Display prediction results\n",
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Get prediction images\n",
    "pred_dir = '/content/runs/predictions'\n",
    "result_images = glob.glob(f'{pred_dir}/*.jpg') + glob.glob(f'{pred_dir}/*.png')\n",
    "\n",
    "print(f\"Showing {min(6, len(result_images))} prediction results:\\n\")\n",
    "\n",
    "for img_path in result_images[:6]:\n",
    "    print(f\"Image: {os.path.basename(img_path)}\")\n",
    "    display(Image(filename=img_path, width=500))\n",
    "    print(\"-\" * 50)"
   ],
   "metadata": {
    "id": "display_predictions"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Step 9: Download Trained Model"
   ],
   "metadata": {
    "id": "step9_header"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Download the best model weights\n",
    "print(\"Downloading best.pt (your trained model)...\")\n",
    "files.download('/content/runs/salt_crystal_model/weights/best.pt')"
   ],
   "metadata": {
    "id": "download_model"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Optional: Download last checkpoint as backup\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Downloading last.pt (backup checkpoint)...\")\n",
    "files.download('/content/runs/salt_crystal_model/weights/last.pt')"
   ],
   "metadata": {
    "id": "download_last"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Local Deployment Guide\n",
    "\n",
    "After downloading `best.pt`, use these code snippets on your local machine:\n",
    "\n",
    "### Install Requirements\n",
    "```bash\n",
    "pip install ultralytics opencv-python\n",
    "```\n",
    "\n",
    "### Run Inference\n",
    "```python\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load model\n",
    "model = YOLO('best.pt')\n",
    "\n",
    "# Predict on image\n",
    "results = model.predict('salt_sample.jpg', conf=0.5)\n",
    "results[0].show()\n",
    "\n",
    "# Predict on webcam\n",
    "results = model.predict(source=0, show=True)\n",
    "```"
   ],
   "metadata": {
    "id": "deployment_guide"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "## Troubleshooting\n",
    "\n",
    "### GPU Memory Error\n",
    "Reduce batch size in training cell: `batch=8` or `batch=4`\n",
    "\n",
    "### Low Accuracy\n",
    "- Add more labeled images (500+)\n",
    "- Use larger model: `yolov8s.pt`\n",
    "- Increase epochs: `epochs=200`\n",
    "\n",
    "### Runtime Disconnects\n",
    "- Enable background execution\n",
    "- Use Colab Pro for longer sessions"
   ],
   "metadata": {
    "id": "troubleshooting"
   }
  }
 ]
}