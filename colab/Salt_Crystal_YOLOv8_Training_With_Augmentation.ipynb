{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# üßÇ Salt Crystal Purity Classification - YOLOv8 Training\n",
        "### With Data Augmentation for Better Results\n",
        "\n",
        "This notebook trains a YOLOv8 model to classify salt crystals as **pure** or **impure**.\n",
        "\n",
        "**What's New:** Added data augmentation step to multiply your dataset 3x for better model performance!\n",
        "\n",
        "## Requirements\n",
        "- Dataset labeled in Label Studio (YOLO format), zipped\n",
        "- Google Colab with GPU runtime\n",
        "\n",
        "## Before Starting\n",
        "1. Go to **Runtime > Change runtime type**\n",
        "2. Select **T4 GPU** (or any available GPU)\n",
        "3. Click **Save**"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 1: Check GPU & Install Dependencies"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Ultralytics (YOLOv8) and Albumentations (for augmentation)\n",
        "!pip install ultralytics albumentations -q\n",
        "\n",
        "# Verify installation\n",
        "import ultralytics\n",
        "ultralytics.checks()\n",
        "\n",
        "import albumentations as A\n",
        "print(f\"\\nAlbumentations version: {A.__version__}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 2: Mount Google Drive & Load Dataset\n",
        "\n",
        "Your dataset is stored in Google Drive at `MyDrive/salt-crystal/data.zip`"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to your dataset in Google Drive\n",
        "zip_path = '/content/drive/MyDrive/salt-crystal/data.zip'\n",
        "\n",
        "# Verify the file exists\n",
        "if os.path.exists(zip_path):\n",
        "    print(f\"\\n‚úÖ Dataset found: {zip_path}\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå ERROR: Dataset not found at {zip_path}\")\n",
        "    print(\"Please check the path and try again.\")\n",
        "\n",
        "# Extract the dataset\n",
        "print(\"\\nExtracting dataset...\")\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/dataset')\n",
        "\n",
        "print(\"‚úÖ Dataset extracted successfully!\")\n",
        "print(\"\\nExtracted contents:\")\n",
        "!ls -la /content/dataset"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Explore the dataset structure\n",
        "import os\n",
        "\n",
        "def list_directory(path, indent=0):\n",
        "    \"\"\"List directory contents recursively (2 levels deep)\"\"\"\n",
        "    if indent > 2:\n",
        "        return\n",
        "    try:\n",
        "        items = os.listdir(path)\n",
        "        for item in items[:10]:\n",
        "            full_path = os.path.join(path, item)\n",
        "            if os.path.isdir(full_path):\n",
        "                print(\"  \" * indent + f\"üìÅ {item}/\")\n",
        "                list_directory(full_path, indent + 1)\n",
        "            else:\n",
        "                print(\"  \" * indent + f\"   üìÑ {item}\")\n",
        "        if len(items) > 10:\n",
        "            print(\"  \" * indent + f\"   ... and {len(items) - 10} more files\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "print(\"Dataset structure:\")\n",
        "print(\"=\" * 50)\n",
        "list_directory('/content/dataset')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 3: Verify Dataset Paths\n",
        "\n",
        "Label Studio exports data with `images/` and `labels/` folders. Let's verify the paths."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Label Studio YOLO export structure:\n",
        "# - images/    (contains all images)\n",
        "# - labels/    (contains YOLO format .txt files)\n",
        "# - classes.txt (contains class names)\n",
        "\n",
        "SOURCE_IMAGES = '/content/dataset/images'\n",
        "SOURCE_LABELS = '/content/dataset/labels'\n",
        "\n",
        "import os\n",
        "\n",
        "if os.path.exists(SOURCE_IMAGES):\n",
        "    num_images = len([f for f in os.listdir(SOURCE_IMAGES) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "    print(f\"‚úÖ Images folder found: {SOURCE_IMAGES}\")\n",
        "    print(f\"   Contains {num_images} images\")\n",
        "else:\n",
        "    print(f\"‚ùå WARNING: Images folder NOT found at {SOURCE_IMAGES}\")\n",
        "\n",
        "if os.path.exists(SOURCE_LABELS):\n",
        "    num_labels = len([f for f in os.listdir(SOURCE_LABELS) if f.endswith('.txt')])\n",
        "    print(f\"‚úÖ Labels folder found: {SOURCE_LABELS}\")\n",
        "    print(f\"   Contains {num_labels} label files\")\n",
        "else:\n",
        "    print(f\"‚ùå WARNING: Labels folder NOT found at {SOURCE_LABELS}\")\n",
        "\n",
        "# Check classes.txt\n",
        "classes_file = '/content/dataset/classes.txt'\n",
        "if os.path.exists(classes_file):\n",
        "    with open(classes_file, 'r') as f:\n",
        "        classes = [line.strip() for line in f.readlines() if line.strip()]\n",
        "    print(f\"\\n‚úÖ Classes found in classes.txt:\")\n",
        "    for i, cls in enumerate(classes):\n",
        "        print(f\"   {i}: {cls}\")\n",
        "else:\n",
        "    print(f\"\\n‚ùå WARNING: classes.txt not found at {classes_file}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üÜï Step 4: Data Augmentation\n",
        "\n",
        "This is the **NEW STEP** that multiplies your dataset!\n",
        "\n",
        "**What it does:**\n",
        "- Takes your 360 original images\n",
        "- Creates 3 augmented versions of each image\n",
        "- Automatically adjusts bounding box coordinates\n",
        "- Results in ~1,440 total images (360 original + 1,080 augmented)\n",
        "\n",
        "**Augmentations applied:**\n",
        "- Horizontal Flip\n",
        "- Random Brightness & Contrast\n",
        "- Slight Rotation (¬±10¬∞)\n",
        "- Gaussian Noise\n",
        "- Blur"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import albumentations as A\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# Configuration\n",
        "SOURCE_IMAGES = '/content/dataset/images'\n",
        "SOURCE_LABELS = '/content/dataset/labels'\n",
        "AUG_IMAGES = '/content/dataset/images_augmented'\n",
        "AUG_LABELS = '/content/dataset/labels_augmented'\n",
        "NUM_AUGMENTATIONS = 3  # Number of augmented versions per image\n",
        "\n",
        "# Create output directories\n",
        "os.makedirs(AUG_IMAGES, exist_ok=True)\n",
        "os.makedirs(AUG_LABELS, exist_ok=True)\n",
        "\n",
        "# Define augmentation pipeline\n",
        "transform = A.Compose([\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "    A.Rotate(limit=10, p=0.4, border_mode=cv2.BORDER_CONSTANT),\n",
        "    A.GaussNoise(var_limit=(10, 50), p=0.3),\n",
        "    A.OneOf([\n",
        "        A.MotionBlur(blur_limit=3, p=0.5),\n",
        "        A.GaussianBlur(blur_limit=3, p=0.5),\n",
        "    ], p=0.2),\n",
        "    A.CLAHE(clip_limit=2.0, p=0.2),  # Improve contrast\n",
        "], bbox_params=A.BboxParams(\n",
        "    format='yolo',\n",
        "    label_fields=['class_labels'],\n",
        "    min_visibility=0.3  # Keep boxes that are at least 30% visible\n",
        "))\n",
        "\n",
        "print(\"üîÑ Starting Data Augmentation...\")\n",
        "print(f\"   Creating {NUM_AUGMENTATIONS} augmented versions per image\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get all image files\n",
        "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
        "image_files = [f for f in os.listdir(SOURCE_IMAGES) if f.lower().endswith(image_extensions)]\n",
        "\n",
        "print(f\"Found {len(image_files)} original images\")\n",
        "\n",
        "# First, copy all original images and labels to augmented folders\n",
        "print(\"\\nüìã Copying original images...\")\n",
        "for img_file in tqdm(image_files, desc=\"Copying originals\"):\n",
        "    # Copy original image\n",
        "    img_path = os.path.join(SOURCE_IMAGES, img_file)\n",
        "    img = cv2.imread(img_path)\n",
        "    cv2.imwrite(os.path.join(AUG_IMAGES, img_file), img)\n",
        "    \n",
        "    # Copy original label\n",
        "    name = os.path.splitext(img_file)[0]\n",
        "    label_path = os.path.join(SOURCE_LABELS, f\"{name}.txt\")\n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            content = f.read()\n",
        "        with open(os.path.join(AUG_LABELS, f\"{name}.txt\"), 'w') as f:\n",
        "            f.write(content)\n",
        "\n",
        "print(f\"‚úÖ Copied {len(image_files)} original images\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now create augmented versions\n",
        "print(\"\\nüé® Creating augmented versions...\")\n",
        "augmented_count = 0\n",
        "skipped_count = 0\n",
        "\n",
        "for img_file in tqdm(image_files, desc=\"Augmenting\"):\n",
        "    img_path = os.path.join(SOURCE_IMAGES, img_file)\n",
        "    name = os.path.splitext(img_file)[0]\n",
        "    ext = os.path.splitext(img_file)[1]\n",
        "    label_path = os.path.join(SOURCE_LABELS, f\"{name}.txt\")\n",
        "    \n",
        "    # Read image\n",
        "    image = cv2.imread(img_path)\n",
        "    if image is None:\n",
        "        skipped_count += 1\n",
        "        continue\n",
        "    \n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    # Read labels (YOLO format: class x_center y_center width height)\n",
        "    bboxes = []\n",
        "    class_labels = []\n",
        "    \n",
        "    if os.path.exists(label_path):\n",
        "        with open(label_path, 'r') as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split()\n",
        "                if len(parts) >= 5:\n",
        "                    class_labels.append(parts[0])\n",
        "                    # YOLO format: x_center, y_center, width, height (normalized)\n",
        "                    bbox = [float(x) for x in parts[1:5]]\n",
        "                    # Clamp values to valid range\n",
        "                    bbox = [max(0.001, min(0.999, x)) for x in bbox]\n",
        "                    bboxes.append(bbox)\n",
        "    \n",
        "    # Create multiple augmented versions\n",
        "    for aug_idx in range(NUM_AUGMENTATIONS):\n",
        "        try:\n",
        "            # Apply augmentation\n",
        "            augmented = transform(\n",
        "                image=image,\n",
        "                bboxes=bboxes,\n",
        "                class_labels=class_labels\n",
        "            )\n",
        "            \n",
        "            aug_image = augmented['image']\n",
        "            aug_bboxes = augmented['bboxes']\n",
        "            aug_class_labels = augmented['class_labels']\n",
        "            \n",
        "            # Save augmented image\n",
        "            aug_name = f\"{name}_aug{aug_idx + 1}\"\n",
        "            aug_image_bgr = cv2.cvtColor(aug_image, cv2.COLOR_RGB2BGR)\n",
        "            cv2.imwrite(os.path.join(AUG_IMAGES, f\"{aug_name}{ext}\"), aug_image_bgr)\n",
        "            \n",
        "            # Save augmented labels\n",
        "            with open(os.path.join(AUG_LABELS, f\"{aug_name}.txt\"), 'w') as f:\n",
        "                for cls, bbox in zip(aug_class_labels, aug_bboxes):\n",
        "                    # Ensure values are within valid range\n",
        "                    bbox = [max(0.001, min(0.999, x)) for x in bbox]\n",
        "                    f.write(f\"{cls} {' '.join(f'{x:.6f}' for x in bbox)}\\n\")\n",
        "            \n",
        "            augmented_count += 1\n",
        "            \n",
        "        except Exception as e:\n",
        "            # Skip if augmentation fails (e.g., bbox goes out of bounds)\n",
        "            skipped_count += 1\n",
        "            continue\n",
        "\n",
        "print(f\"\\n\" + \"=\" * 50)\n",
        "print(f\"‚úÖ AUGMENTATION COMPLETE!\")\n",
        "print(f\"=\" * 50)\n",
        "print(f\"   Original images:  {len(image_files)}\")\n",
        "print(f\"   Augmented images: {augmented_count}\")\n",
        "print(f\"   Total images:     {len(image_files) + augmented_count}\")\n",
        "if skipped_count > 0:\n",
        "    print(f\"   Skipped:          {skipped_count} (due to errors)\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some augmented samples\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "# Get a random original image\n",
        "sample_img = random.choice(image_files)\n",
        "sample_name = os.path.splitext(sample_img)[0]\n",
        "sample_ext = os.path.splitext(sample_img)[1]\n",
        "\n",
        "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "\n",
        "# Original\n",
        "orig_path = os.path.join(AUG_IMAGES, sample_img)\n",
        "if os.path.exists(orig_path):\n",
        "    img = cv2.imread(orig_path)\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    axes[0].imshow(img)\n",
        "    axes[0].set_title('Original', fontsize=12)\n",
        "    axes[0].axis('off')\n",
        "\n",
        "# Augmented versions\n",
        "for i in range(3):\n",
        "    aug_path = os.path.join(AUG_IMAGES, f\"{sample_name}_aug{i+1}{sample_ext}\")\n",
        "    if os.path.exists(aug_path):\n",
        "        img = cv2.imread(aug_path)\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        axes[i+1].imshow(img)\n",
        "        axes[i+1].set_title(f'Augmented {i+1}', fontsize=12)\n",
        "        axes[i+1].axis('off')\n",
        "\n",
        "plt.suptitle(f'Sample: {sample_name}', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüëÜ Above shows one original image and its 3 augmented versions\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update source paths to use augmented data for the rest of the pipeline\n",
        "SOURCE_IMAGES = '/content/dataset/images_augmented'\n",
        "SOURCE_LABELS = '/content/dataset/labels_augmented'\n",
        "\n",
        "print(\"‚úÖ Source paths updated to use augmented dataset\")\n",
        "print(f\"   Images: {SOURCE_IMAGES}\")\n",
        "print(f\"   Labels: {SOURCE_LABELS}\")\n",
        "print(f\"\\n   Total images available: {len(os.listdir(SOURCE_IMAGES))}\")\n",
        "print(f\"   Total labels available: {len(os.listdir(SOURCE_LABELS))}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 5: Organize Dataset (Train/Validation Split)\n",
        "\n",
        "Now we split the augmented dataset into training and validation sets."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "\n",
        "# Use augmented data paths\n",
        "SOURCE_IMAGES = '/content/dataset/images_augmented'\n",
        "SOURCE_LABELS = '/content/dataset/labels_augmented'\n",
        "\n",
        "# Create train/valid directories\n",
        "os.makedirs('/content/dataset/train/images', exist_ok=True)\n",
        "os.makedirs('/content/dataset/train/labels', exist_ok=True)\n",
        "os.makedirs('/content/dataset/valid/images', exist_ok=True)\n",
        "os.makedirs('/content/dataset/valid/labels', exist_ok=True)\n",
        "\n",
        "# Get all image files from augmented folder\n",
        "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.webp')\n",
        "image_files = [f for f in os.listdir(SOURCE_IMAGES) if f.lower().endswith(image_extensions)]\n",
        "\n",
        "print(f\"Found {len(image_files)} total images (original + augmented)\")\n",
        "\n",
        "# Shuffle for random split\n",
        "random.seed(42)  # For reproducibility\n",
        "random.shuffle(image_files)\n",
        "\n",
        "# Split 90% train, 10% validation\n",
        "split_idx = int(len(image_files) * 0.9)\n",
        "train_files = image_files[:split_idx]\n",
        "valid_files = image_files[split_idx:]\n",
        "\n",
        "print(f\"\\nüìä Dataset Split:\")\n",
        "print(f\"   Training set:   {len(train_files)} images (90%)\")\n",
        "print(f\"   Validation set: {len(valid_files)} images (10%)\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy files to train folder\n",
        "print(\"\\nüìã Copying training files...\")\n",
        "for img in tqdm(train_files, desc=\"Training set\"):\n",
        "    # Copy image\n",
        "    shutil.copy(os.path.join(SOURCE_IMAGES, img), '/content/dataset/train/images/')\n",
        "    # Copy corresponding label\n",
        "    label = os.path.splitext(img)[0] + '.txt'\n",
        "    label_path = os.path.join(SOURCE_LABELS, label)\n",
        "    if os.path.exists(label_path):\n",
        "        shutil.copy(label_path, '/content/dataset/train/labels/')\n",
        "\n",
        "# Copy files to valid folder\n",
        "print(\"\\nüìã Copying validation files...\")\n",
        "for img in tqdm(valid_files, desc=\"Validation set\"):\n",
        "    # Copy image\n",
        "    shutil.copy(os.path.join(SOURCE_IMAGES, img), '/content/dataset/valid/images/')\n",
        "    # Copy corresponding label\n",
        "    label = os.path.splitext(img)[0] + '.txt'\n",
        "    label_path = os.path.join(SOURCE_LABELS, label)\n",
        "    if os.path.exists(label_path):\n",
        "        shutil.copy(label_path, '/content/dataset/valid/labels/')\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"‚úÖ Dataset organization complete!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"   Train images: {len(os.listdir('/content/dataset/train/images'))}\")\n",
        "print(f\"   Train labels: {len(os.listdir('/content/dataset/train/labels'))}\")\n",
        "print(f\"   Valid images: {len(os.listdir('/content/dataset/valid/images'))}\")\n",
        "print(f\"   Valid labels: {len(os.listdir('/content/dataset/valid/labels'))}\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 6: Create Dataset Configuration (YAML)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Read class names from Label Studio's classes.txt\n",
        "classes_file = '/content/dataset/classes.txt'\n",
        "\n",
        "with open(classes_file, 'r') as f:\n",
        "    classes = [line.strip() for line in f.readlines() if line.strip()]\n",
        "\n",
        "print(f\"Found {len(classes)} classes: {classes}\")\n",
        "\n",
        "# Build YAML configuration dynamically\n",
        "yaml_lines = [\n",
        "    \"path: /content/dataset\",\n",
        "    \"train: train/images\",\n",
        "    \"val: valid/images\",\n",
        "    \"\",\n",
        "    \"names:\"\n",
        "]\n",
        "\n",
        "for i, cls in enumerate(classes):\n",
        "    yaml_lines.append(f\"  {i}: {cls}\")\n",
        "\n",
        "yaml_content = \"\\n\".join(yaml_lines)\n",
        "\n",
        "# Write YAML file\n",
        "with open('/content/dataset/salt_crystal.yaml', 'w') as f:\n",
        "    f.write(yaml_content)\n",
        "\n",
        "print(\"\\n‚úÖ Dataset configuration file created!\")\n",
        "print(\"=\" * 50)\n",
        "print(yaml_content)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify class labels in your dataset\n",
        "import os\n",
        "\n",
        "label_dir = '/content/dataset/train/labels'\n",
        "label_files = os.listdir(label_dir)[:3]\n",
        "\n",
        "print(\"Sample label files content:\")\n",
        "print(\"(Format: class_id x_center y_center width height)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for lf in label_files:\n",
        "    print(f\"\\n{lf}:\")\n",
        "    with open(os.path.join(label_dir, lf), 'r') as f:\n",
        "        content = f.read().strip()\n",
        "        print(content if content else \"  (empty file)\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 7: Train YOLOv8 Model\n",
        "\n",
        "### Model Options:\n",
        "| Model | Size | Speed | Accuracy |\n",
        "|-------|------|-------|----------|\n",
        "| yolov8n.pt | Nano | Fastest | Good |\n",
        "| yolov8s.pt | Small | Fast | Better |\n",
        "| yolov8m.pt | Medium | Moderate | High |\n",
        "| yolov8l.pt | Large | Slower | Highest |"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a pretrained YOLOv8 model\n",
        "# Using yolov8s.pt (Small) for better accuracy with augmented data\n",
        "model = YOLO('yolov8s.pt')\n",
        "\n",
        "# Train the model\n",
        "results = model.train(\n",
        "    data='/content/dataset/salt_crystal.yaml',\n",
        "    epochs=100,           # Number of training epochs\n",
        "    imgsz=640,            # Image size\n",
        "    batch=16,             # Batch size (reduce to 8 if memory error)\n",
        "    patience=20,          # Early stopping patience\n",
        "    save=True,            # Save checkpoints\n",
        "    project='/content/runs',\n",
        "    name='salt_crystal_model',\n",
        "    exist_ok=True,        # Overwrite if exists\n",
        "    pretrained=True,      # Use pretrained weights\n",
        "    optimizer='auto',     # Automatic optimizer selection\n",
        "    verbose=True,         # Print training progress\n",
        "    seed=42,              # For reproducibility\n",
        "    \n",
        "    # Augmentation settings (YOLOv8 built-in - complements our offline augmentation)\n",
        "    augment=True,         # Enable built-in augmentation\n",
        "    hsv_h=0.015,          # HSV-Hue augmentation\n",
        "    hsv_s=0.7,            # HSV-Saturation augmentation\n",
        "    hsv_v=0.4,            # HSV-Value augmentation\n",
        "    degrees=0.0,          # Rotation (we already did this offline)\n",
        "    translate=0.1,        # Translation\n",
        "    scale=0.5,            # Scale\n",
        "    fliplr=0.5,           # Horizontal flip\n",
        "    mosaic=1.0,           # Mosaic augmentation\n",
        ")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 8: Evaluate Model Performance"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load the best trained model\n",
        "model = YOLO('/content/runs/salt_crystal_model/weights/best.pt')\n",
        "\n",
        "# Validate on validation set\n",
        "metrics = model.val()\n",
        "\n",
        "# Print metrics\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"üìä MODEL PERFORMANCE METRICS\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"mAP50:      {metrics.box.map50:.4f}  (Mean Average Precision @ IoU 50%)\")\n",
        "print(f\"mAP50-95:   {metrics.box.map:.4f}  (Mean AP across IoU thresholds)\")\n",
        "print(f\"Precision:  {metrics.box.mp:.4f}  (How many detections are correct)\")\n",
        "print(f\"Recall:     {metrics.box.mr:.4f}  (How many objects were detected)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "if metrics.box.map50 > 0.8:\n",
        "    print(\"\\nüéâ Model performance is EXCELLENT!\")\n",
        "elif metrics.box.map50 > 0.7:\n",
        "    print(\"\\n‚úÖ Model performance is GOOD!\")\n",
        "elif metrics.box.map50 > 0.5:\n",
        "    print(\"\\n‚ö†Ô∏è Model performance is ACCEPTABLE. Consider more training data for improvement.\")\n",
        "else:\n",
        "    print(\"\\n‚ùå Model performance needs improvement. Try:\\n- More labeled images\\n- Larger model (yolov8m.pt)\\n- More epochs\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View training results plots\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "results_dir = '/content/runs/salt_crystal_model'\n",
        "\n",
        "# Display confusion matrix\n",
        "if os.path.exists(f'{results_dir}/confusion_matrix.png'):\n",
        "    print(\"üìä Confusion Matrix:\")\n",
        "    display(Image(filename=f'{results_dir}/confusion_matrix.png', width=600))\n",
        "\n",
        "# Display training results\n",
        "if os.path.exists(f'{results_dir}/results.png'):\n",
        "    print(\"\\nüìà Training Results:\")\n",
        "    display(Image(filename=f'{results_dir}/results.png', width=800))"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 9: Test Predictions on Sample Images"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "\n",
        "# Load trained model\n",
        "model = YOLO('/content/runs/salt_crystal_model/weights/best.pt')\n",
        "\n",
        "# Run inference on validation images\n",
        "results = model.predict(\n",
        "    source='/content/dataset/valid/images',\n",
        "    save=True,\n",
        "    conf=0.5,  # Confidence threshold\n",
        "    project='/content/runs',\n",
        "    name='predictions',\n",
        "    exist_ok=True\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Predictions complete!\")"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display prediction results\n",
        "from IPython.display import Image, display\n",
        "import glob\n",
        "import os\n",
        "\n",
        "# Get prediction images\n",
        "pred_dir = '/content/runs/predictions'\n",
        "result_images = glob.glob(f'{pred_dir}/*.jpg') + glob.glob(f'{pred_dir}/*.png')\n",
        "\n",
        "print(f\"Showing {min(6, len(result_images))} prediction results:\\n\")\n",
        "\n",
        "for img_path in result_images[:6]:\n",
        "    print(f\"üñºÔ∏è Image: {os.path.basename(img_path)}\")\n",
        "    display(Image(filename=img_path, width=500))\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Step 10: Download Trained Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the best model weights\n",
        "print(\"üì• Downloading best.pt (your trained model)...\")\n",
        "files.download('/content/runs/salt_crystal_model/weights/best.pt')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optional: Download last checkpoint as backup\n",
        "from google.colab import files\n",
        "\n",
        "print(\"üì• Downloading last.pt (backup checkpoint)...\")\n",
        "files.download('/content/runs/salt_crystal_model/weights/last.pt')"
      ],
      "metadata": {},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üìã Summary: What Changed with Augmentation\n",
        "\n",
        "| Metric | Before (No Augmentation) | After (With Augmentation) |\n",
        "|--------|--------------------------|---------------------------|\n",
        "| Original Images | 360 | 360 |\n",
        "| Total Training Images | ~324 | ~1,296 |\n",
        "| Data Variety | Low | High |\n",
        "| Overfitting Risk | High | Lower |\n",
        "| Expected Accuracy | Moderate | Higher |\n",
        "\n",
        "### Augmentations Applied:\n",
        "- ‚úÖ Horizontal Flip (50% chance)\n",
        "- ‚úÖ Brightness & Contrast adjustment\n",
        "- ‚úÖ Rotation (¬±10¬∞)\n",
        "- ‚úÖ Gaussian Noise\n",
        "- ‚úÖ Motion/Gaussian Blur\n",
        "- ‚úÖ CLAHE (Contrast enhancement)"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üñ•Ô∏è Local Deployment Guide\n",
        "\n",
        "After downloading `best.pt`, use these code snippets on your local machine:\n",
        "\n",
        "### Install Requirements\n",
        "```bash\n",
        "pip install ultralytics opencv-python\n",
        "```\n",
        "\n",
        "### Run Inference\n",
        "```python\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load model\n",
        "model = YOLO('best.pt')\n",
        "\n",
        "# Predict on image\n",
        "results = model.predict('salt_sample.jpg', conf=0.5)\n",
        "results[0].show()\n",
        "\n",
        "# Predict on webcam\n",
        "results = model.predict(source=0, show=True)\n",
        "```"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## üîß Troubleshooting\n",
        "\n",
        "### GPU Memory Error\n",
        "Reduce batch size in training cell: `batch=8` or `batch=4`\n",
        "\n",
        "### Low Accuracy\n",
        "- Add more labeled images (500+)\n",
        "- Use larger model: `yolov8m.pt`\n",
        "- Increase epochs: `epochs=150`\n",
        "- Increase `NUM_AUGMENTATIONS` to 5\n",
        "\n",
        "### Runtime Disconnects\n",
        "- Enable background execution\n",
        "- Use Colab Pro for longer sessions\n",
        "\n",
        "### Augmentation Errors\n",
        "- Some images may be skipped if bounding boxes go out of bounds\n",
        "- This is normal and handled automatically"
      ],
      "metadata": {}
    }
  ]
}
